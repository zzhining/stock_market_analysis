{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOwQD9sruV7uTaP8RbN0zni",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzhining/stock_market_analysis/blob/main/4%EC%A3%BC%EC%B0%A8/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%88%98%EC%A7%911.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 구글 HTML 읽어오기"
      ],
      "metadata": {
        "id": "zBmuPsy_r8H4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilz_p2YLrVLt"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://www.google.com/'\n",
        "reponse = requests.get(url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reponse.status_code"
      ],
      "metadata": {
        "id": "9YgOAitpsTED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reponse.text"
      ],
      "metadata": {
        "id": "qjkQXvfbsZ1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://search.naver.com/search.naver?query=%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D'\n",
        "response = requests.get(url)\n",
        "response.text"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mpBqQS_UsccA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이미지 가져오기"
      ],
      "metadata": {
        "id": "77XLi4rJre5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.google.com/images/branding/googlelogo/1x/googlelogo_light_color_272x92dp.png'\n",
        "\n",
        "response = requests.get(url)"
      ],
      "metadata": {
        "id": "1utV0Np9tEUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.status_code"
      ],
      "metadata": {
        "id": "BHaJpr3chI_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "Image.open(BytesIO(response.content))"
      ],
      "metadata": {
        "id": "q9J0M0hthI8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "name = os.path.basename(url)"
      ],
      "metadata": {
        "id": "gSctVimchI5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd() #현재 작업 경로"
      ],
      "metadata": {
        "id": "0gjOS_qrl9G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder = f'{os.getcwd()}/image'"
      ],
      "metadata": {
        "id": "eigALqkrhI3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# folder 경로가 없다면 folder 경로를 생성하기\n",
        "if not os.path.isdir(folder):\n",
        "    os.mkdir(folder)"
      ],
      "metadata": {
        "id": "ZECAVjyGhI0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = os.path.join(folder, name)"
      ],
      "metadata": {
        "id": "Kh14cWWehIyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = open(image_path, 'wb') #image_path를 wb 모드로 오픈"
      ],
      "metadata": {
        "id": "SpkwaDxphIdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.write(response.content) # response.content를 image 객체에 쓰기"
      ],
      "metadata": {
        "id": "It0wCgPHm1pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.close()"
      ],
      "metadata": {
        "id": "8SAlYDG1m1mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 블로그 실습"
      ],
      "metadata": {
        "id": "gNNlQluWrhNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L -O https://raw.githubusercontent.com/zzhining/python_data_basic/main/5%EC%9E%A5/index.html"
      ],
      "metadata": {
        "id": "RVLPwFLFhIa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# requests 대신에 index.html 파일을 직접 읽어오기\n",
        "filename = \"index.html\"\n",
        "html = \"\"\n",
        "with open (filename, 'r', encoding='UTF-8') as file:  \n",
        "    for line in file:               \n",
        "        html += line\n",
        "html"
      ],
      "metadata": {
        "collapsed": true,
        "id": "661Btt6ym1kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(html, 'lxml')"
      ],
      "metadata": {
        "id": "OaNO2mqbm1hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_list = soup.find_all('div', {'class': \"post-preview\"})"
      ],
      "metadata": {
        "id": "oiD7OdSDm1fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title_list = []\n",
        "subtitle_list= []\n",
        "date_list = []\n",
        "\n",
        "for post in post_list:\n",
        "    title = post.find('h2', {'class':\"post-title\"}).text.strip()\n",
        "    subtitle = post.find('h3').text.strip()\n",
        "    date = post.find('p').text.strip()\n",
        "    title_list.append(title)\n",
        "    subtitle_list.append(subtitle)\n",
        "    date_list.append(date)"
      ],
      "metadata": {
        "id": "ze1r32efm1b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({'title': title_list, 'subtitle': subtitle_list, 'date': date_list})\n",
        "df"
      ],
      "metadata": {
        "id": "hOxp75mysoja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 신문기사 스크랩"
      ],
      "metadata": {
        "id": "rLlhRJgjqkUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "url = 'https://finance.naver.com/news/news_read.naver?article_id=0004876048&office_id=008&mode=mainnews&type=&date=2023-04-17&page=1'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'lxml')\n",
        "soup.find('div', {'class': 'articleCont'}).text"
      ],
      "metadata": {
        "id": "3GKjT5MihOIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 쇼핑몰 데이터"
      ],
      "metadata": {
        "id": "iF-S2j6Cqr1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# http://www.neweracapkorea.com/shop/shopbrand.html?xcode=031&mcode=002&type=Y&gf_ref=Yz1vU0FlS3M=\n",
        "base_url = \"http://www.neweracapkorea.com\"\n",
        "cap_total_url = \"/shop/shopbrand.html?xcode=031&mcode=002&type=Y&gf_ref=Yz1vU0FlS3M=\"\n",
        "base_url + cap_total_url"
      ],
      "metadata": {
        "id": "IwyLc9Xfsog-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get html\n",
        "response = requests.get(base_url+cap_total_url)\n",
        "\n",
        "# BeautifulSoup을 활용하여 데이터 파싱\n",
        "soup = BeautifulSoup(response.content, \"lxml\")\n",
        "\n",
        "name_list = []\n",
        "price_list = []\n",
        "url_list = []\n",
        "\n",
        "cap_info = soup.findAll('div', {'class':'tb-center'})\n",
        "\n",
        "for cap in cap_info:\n",
        "    name = cap.find('li', {'class':'dsc'}).text\n",
        "    price = cap.find('li', {'class':'price'}).text\n",
        "    url = cap.find('a').get('href')\n",
        "    # print(\"이름: {}, 가격: {}\".format(name, price))\n",
        "    name_list.append(name)\n",
        "    price_list.append(price)\n",
        "    url_list.append(url)\n",
        "df = pd.DataFrame({\"이름\": name_list, \"가격\" : price_list, \"url\": url_list})\n",
        "df.head()"
      ],
      "metadata": {
        "id": "6kCTMR7wsoed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap_detail_df = pd.DataFrame()\n",
        "\n",
        "for i in range(len(df)):\n",
        "    print(i , end='... ')\n",
        "    # (1)df에 저장된 url 읽어오기\n",
        "    url = df['url'][i]\n",
        "    response = requests.get(base_url + url)\n",
        "    soup = BeautifulSoup(response.content, \"lxml\")\n",
        "    \n",
        "    # (2)상세페이지의 정보 파싱\n",
        "    cap_name = soup.find('h3', {'class':'tit-prd'}).text.strip()\n",
        "    cap_info = soup.find('tbody')\n",
        "    features = cap_info.findAll('div', {'class':'tb-left'})\n",
        "    \n",
        "    fic_list = []\n",
        "    for f in features:\n",
        "        fic_list.append(f.text.strip())\n",
        "    \n",
        "    # (3)파싱한 정보를 사용하여 딕셔너리 생성\n",
        "    cap_dict = {'제품명': cap_name}\n",
        "\n",
        "    if len(fic_list) % 2 != 0:\n",
        "        fic_list = fic_list[1:] \n",
        "\n",
        "    for i in range(len(fic_list)):\n",
        "        if i % 2 == 0:\n",
        "            if fic_list[i] != '':\n",
        "                cap_dict.update({fic_list[i]: fic_list[i+1]})\n",
        "    \n",
        "    # (4)생성한 딕셔너리로 데이터프레임 생성\n",
        "    temp_df = pd.DataFrame(data = cap_dict,  index = [0])\n",
        "\n",
        "    # (5) 데이터프레임 추가\n",
        "    if len(cap_detail_df) == 0:\n",
        "        cap_detail_df = temp_df\n",
        "    else:\n",
        "        cap_detail_df = cap_detail_df.append(temp_df, ignore_index = True)\n",
        "\n",
        "cap_detail_df.head()"
      ],
      "metadata": {
        "id": "8zI0re8usoXF",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"http://www.neweracapkorea.com\"\n",
        "\n",
        "name_list = []\n",
        "price_list = []\n",
        "url_list = []\n",
        "index = 1\n",
        "\n",
        "while True: \n",
        "    try :\n",
        "        print('{} 페이지 파싱.....'.format(index))\n",
        "        page_url = f\"/shop/shopbrand.html?type=Y&xcode=031&mcode=002&sort=&page={index}\"\n",
        "        response = requests.get(base_url+page_url)\n",
        "\n",
        "        # BeautifulSoup을 활용하여 데이터 파싱\n",
        "        soup = BeautifulSoup(response.content, \"lxml\")\n",
        "        cap_info = soup.findAll('div', {'class':'tb-center'})\n",
        "\n",
        "        if len(cap_info) == 0 :\n",
        "            print('끝')\n",
        "            break\n",
        "        for cap in cap_info:\n",
        "            name = cap.find('li', {'class':'dsc'}).text\n",
        "            price = cap.find('li', {'class':'price'})\n",
        "            url = cap.find('a').get('href')\n",
        "            #print(\"이름: {}, 가격: {}\".format(name, price))\n",
        "            name_list.append(name)\n",
        "            \n",
        "            if price != None :\n",
        "                price_list.append(price.text)\n",
        "            else :\n",
        "                price_list.append('SOLD OUT')\n",
        "            url_list.append(url)\n",
        "        index = index + 1\n",
        "    except:\n",
        "        print(\"Unexpected error:\", sys.exc_info()[0])\n",
        "        break\n",
        "\n",
        "df = pd.DataFrame({\"이름\": name_list, \"가격\" : price_list, \"url\": url_list})\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "YxMOILPIm1Ze"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}